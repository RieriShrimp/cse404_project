{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "id": "2be60de0-f270-4281-a752-02b38c9664df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize"
=======
   "execution_count": 1,
   "id": "05b04807-c0c0-45d0-9d80-9b14119dc963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
>>>>>>> fc6b3414fec6b2616afaa6b9fc6f56cacced889a
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "id": "b7767381-5f08-45b8-bd3b-58a26da5d91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.77      0.70       798\n",
      "        fear       0.75      0.58      0.65       288\n",
      "         joy       0.69      0.69      0.69       803\n",
      "        love       0.76      0.81      0.78       763\n",
      "     sadness       0.65      0.70      0.67       635\n",
      "    surprise       0.72      0.65      0.69       555\n",
      "       total       0.69      0.06      0.11       158\n",
      "\n",
      "    accuracy                           0.69      4000\n",
      "   macro avg       0.70      0.61      0.61      4000\n",
      "weighted avg       0.70      0.69      0.68      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"final_df.csv\")\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "df = df[:20000]\n",
    "# Separate features and labels\n",
    "X = df[\"text\"]\n",
    "y = df.drop(columns=[\"text\"])\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Flatten the multi-label y into a single label format\n",
    "y_single_label = y.idxmax(axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_single_label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can try different kernels (e.g., 'rbf', 'poly')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
=======
   "execution_count": 23,
   "id": "6f943ad6-1560-4513-b5d9-a6d4650828b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('final_df.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3716200e-e8be-4422-bf80-18cbc37b0535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So happy for [NAME]. So sad he's not here. Ima...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just came home, what the fuck is this lineup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By far the coolest thing I've seen on this thr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466366</th>\n",
       "      <td>@iscreamshinki Oh that's why.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466367</th>\n",
       "      <td>His snoring is so annoying n it keeps me from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466368</th>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466369</th>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466370</th>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466371 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sadness  joy  love  \\\n",
       "0                                         That game hurt.        1    0     0   \n",
       "1                                      Man I love reddit.        0    0     1   \n",
       "2       So happy for [NAME]. So sad he's not here. Ima...        1    1     0   \n",
       "3       I just came home, what the fuck is this lineup...        0    0     1   \n",
       "4       By far the coolest thing I've seen on this thr...        0    1     0   \n",
       "...                                                   ...      ...  ...   ...   \n",
       "466366                      @iscreamshinki Oh that's why.        0    0     0   \n",
       "466367  His snoring is so annoying n it keeps me from ...        0    0     1   \n",
       "466368                     Happy Mothers Day  All my love        0    0     1   \n",
       "466369  Happy Mother's Day to all the mommies out ther...        0    0     1   \n",
       "466370  @mopedronin bullet train from tokyo    the gf ...        0    0     1   \n",
       "\n",
       "        anger  fear  surprise  total  \n",
       "0           0     0         0      1  \n",
       "1           0     0         0      1  \n",
       "2           0     0         0      2  \n",
       "3           0     0         0      1  \n",
       "4           0     0         0      1  \n",
       "...       ...   ...       ...    ...  \n",
       "466366      0     0         1      1  \n",
       "466367      0     0         0      1  \n",
       "466368      0     0         0      1  \n",
       "466369      0     0         0      1  \n",
       "466370      0     0         0      1  \n",
       "\n",
       "[466371 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
>>>>>>> fc6b3414fec6b2616afaa6b9fc6f56cacced889a
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "09b7ec0b-e437-4144-80d8-2de84095a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to numerical features using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Word embeddings using Word2Vec\n",
    "word_embeddings_model = Word2Vec(sentences=X, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_embeddings = np.array([np.mean([word_embeddings_model.wv[word] for word in sentence.split() if word in word_embeddings_model.wv] or [np.zeros(100)], axis=0) for sentence in X])\n",
    "\n",
    "# Combine TF-IDF and word embeddings\n",
    "X_combined = np.hstack((X_tfidf.toarray(), word_embeddings))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can try different kernels (e.g., 'rbf', 'poly')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
=======
   "id": "8695dff2-8952-4354-beb1-72b9d6cc4dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop("
>>>>>>> fc6b3414fec6b2616afaa6b9fc6f56cacced889a
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
